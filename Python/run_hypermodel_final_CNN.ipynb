{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.9.1\n",
      "keras: 2.9.0\n",
      "keras_tuner: 1.1.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"tensorflow:\", tf.__version__)\n",
    "from tensorflow import keras\n",
    "print(\"keras:\", keras.__version__)\n",
    "import keras_tuner as kt\n",
    "print(\"keras_tuner:\", kt.__version__)\n",
    "\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Check if tensorflow can use your GPU\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random_state seed\n",
    "RS = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>architecture</th>\n",
       "      <th>m_set</th>\n",
       "      <th>traits</th>\n",
       "      <th>part</th>\n",
       "      <th>input_type</th>\n",
       "      <th>output_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>MLP</td>\n",
       "      <td>SNP</td>\n",
       "      <td>culm.diameter.1st.internode</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>MLP</td>\n",
       "      <td>SNP</td>\n",
       "      <td>leaf.senescence</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>MLP</td>\n",
       "      <td>SNP</td>\n",
       "      <td>grain.weight</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>MLP</td>\n",
       "      <td>SNP</td>\n",
       "      <td>time.to.flowering.from.sowing</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>MLP</td>\n",
       "      <td>all</td>\n",
       "      <td>culm.diameter.1st.internode</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>MLP</td>\n",
       "      <td>all</td>\n",
       "      <td>leaf.senescence</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>MLP</td>\n",
       "      <td>all</td>\n",
       "      <td>grain.weight</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>MLP</td>\n",
       "      <td>all</td>\n",
       "      <td>time.to.flowering.from.sowing</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>CNN</td>\n",
       "      <td>SNP</td>\n",
       "      <td>culm.diameter.1st.internode</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>CNN</td>\n",
       "      <td>SNP</td>\n",
       "      <td>leaf.senescence</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>CNN</td>\n",
       "      <td>SNP</td>\n",
       "      <td>grain.weight</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>CNN</td>\n",
       "      <td>SNP</td>\n",
       "      <td>time.to.flowering.from.sowing</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>CNN</td>\n",
       "      <td>all</td>\n",
       "      <td>culm.diameter.1st.internode</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>CNN</td>\n",
       "      <td>all</td>\n",
       "      <td>leaf.senescence</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>CNN</td>\n",
       "      <td>all</td>\n",
       "      <td>grain.weight</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>top-markers-10k</td>\n",
       "      <td>CNN</td>\n",
       "      <td>all</td>\n",
       "      <td>time.to.flowering.from.sowing</td>\n",
       "      <td>AroAdm</td>\n",
       "      <td>single-input</td>\n",
       "      <td>single-output</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_type architecture m_set                         traits    part  \\\n",
       "0   top-markers-10k          MLP   SNP    culm.diameter.1st.internode  AroAdm   \n",
       "1   top-markers-10k          MLP   SNP                leaf.senescence  AroAdm   \n",
       "2   top-markers-10k          MLP   SNP                   grain.weight  AroAdm   \n",
       "3   top-markers-10k          MLP   SNP  time.to.flowering.from.sowing  AroAdm   \n",
       "4   top-markers-10k          MLP   all    culm.diameter.1st.internode  AroAdm   \n",
       "5   top-markers-10k          MLP   all                leaf.senescence  AroAdm   \n",
       "6   top-markers-10k          MLP   all                   grain.weight  AroAdm   \n",
       "7   top-markers-10k          MLP   all  time.to.flowering.from.sowing  AroAdm   \n",
       "8   top-markers-10k          CNN   SNP    culm.diameter.1st.internode  AroAdm   \n",
       "9   top-markers-10k          CNN   SNP                leaf.senescence  AroAdm   \n",
       "10  top-markers-10k          CNN   SNP                   grain.weight  AroAdm   \n",
       "11  top-markers-10k          CNN   SNP  time.to.flowering.from.sowing  AroAdm   \n",
       "12  top-markers-10k          CNN   all    culm.diameter.1st.internode  AroAdm   \n",
       "13  top-markers-10k          CNN   all                leaf.senescence  AroAdm   \n",
       "14  top-markers-10k          CNN   all                   grain.weight  AroAdm   \n",
       "15  top-markers-10k          CNN   all  time.to.flowering.from.sowing  AroAdm   \n",
       "\n",
       "      input_type    output_type  \n",
       "0   single-input  single-output  \n",
       "1   single-input  single-output  \n",
       "2   single-input  single-output  \n",
       "3   single-input  single-output  \n",
       "4   single-input  single-output  \n",
       "5   single-input  single-output  \n",
       "6   single-input  single-output  \n",
       "7   single-input  single-output  \n",
       "8   single-input  single-output  \n",
       "9   single-input  single-output  \n",
       "10  single-input  single-output  \n",
       "11  single-input  single-output  \n",
       "12  single-input  single-output  \n",
       "13  single-input  single-output  \n",
       "14  single-input  single-output  \n",
       "15  single-input  single-output  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Obtain parameters for the different analyses ----------------------------------------\n",
    "# par_file = sys.argv[1]\n",
    "# row_number = int(sys.argv[2])\n",
    "\n",
    "# par_file = \"AroAdm_kerPC.csv\"\n",
    "par_file = \"AroAdm_top-markers-10k.csv\"\n",
    "row_number = 11\n",
    "\n",
    "# Load grid\n",
    "par_grid = pd.read_csv(os.path.join(\"parameters\", par_file))\n",
    "par_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_type                    top-markers-10k\n",
      "architecture                              CNN\n",
      "m_set                                     SNP\n",
      "traits          time.to.flowering.from.sowing\n",
      "part                                   AroAdm\n",
      "input_type                       single-input\n",
      "output_type                     single-output\n",
      "Name: 11, dtype: object \n",
      "\n",
      "models/top-markers-10k_CNN_SNP_single-input/time.to.flowering.from.sowing/AroAdm\n",
      "['time.to.flowering.from.sowing']\n",
      "['continuous']\n"
     ]
    }
   ],
   "source": [
    "# Extract parameters =====================================================================\n",
    "\n",
    "# Which row of the grid\n",
    "pars = par_grid.iloc[row_number]\n",
    "print(pars, \"\\n\")\n",
    "\n",
    "# Model type: top-markers-10k or kerPC\n",
    "model_type = pars[\"model_type\"]\n",
    "\n",
    "# Common pars\n",
    "architecture = pars[\"architecture\"]\n",
    "m_set = pars[\"m_set\"]\n",
    "traits = pars[\"traits\"]\n",
    "part = pars[\"part\"]\n",
    "input_type = pars[\"input_type\"]\n",
    "output_type = pars[\"output_type\"]\n",
    "\n",
    "# Output folder\n",
    "out_folder = os.path.join(\"models\", f\"{model_type}_{architecture}_{m_set}_{input_type}\", traits, part)\n",
    "if not os.path.isdir(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "print(out_folder)\n",
    "\n",
    "# Save traits as list\n",
    "# If multi-output, change literal string to list\n",
    "if output_type == \"multi-output\":\n",
    "    traits = ast.literal_eval(traits)\n",
    "else:\n",
    "    traits = [traits]\n",
    "print(traits)\n",
    "\n",
    "# Target variable type\n",
    "# Save as list, just like traits\n",
    "target_dict = {\n",
    "    \"culm.diameter.1st.internode\": \"binary\",\n",
    "    \"leaf.senescence\": \"binary\",\n",
    "    \"grain.weight\": \"continuous\",\n",
    "    \"time.to.flowering.from.sowing\": \"continuous\"\n",
    "}\n",
    "\n",
    "target_types = []\n",
    "for trait_i in traits:\n",
    "    if trait_i not in target_dict.keys():\n",
    "        print(\"Define variable type of the target in the dictionary\")\n",
    "        exit(1)\n",
    "    target_types.append(target_dict[trait_i])\n",
    "\n",
    "print(target_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(738, 10000)\n"
     ]
    }
   ],
   "source": [
    "# 3. Prepare data ------------------------------------------------------------------------\n",
    "\n",
    "# Features ===============================================================================\n",
    "# Generate X_list, even if single-input\n",
    "\n",
    "# Top-markers-10k\n",
    "if model_type == \"top-markers-10k\":\n",
    "    X_list = []\n",
    "    X_scaler_list = []\n",
    "    \n",
    "    # For every trait, 10k most associated markers\n",
    "    for i in range(len(traits)):\n",
    "        X_name = f\"geno_top-10000-{m_set}_{part}_{traits[i]}.csv\"\n",
    "        # Load and remove accession column\n",
    "        X_df = pd.read_csv(os.path.join(\"data\", model_type, X_name))\n",
    "        X_df = X_df.iloc[:, 1:]\n",
    "        \n",
    "        X = X_df.to_numpy()\n",
    "        # Scale using all data because genomic prediction\n",
    "        scaler_X_all = StandardScaler()\n",
    "        scaler_X_all.fit(X)\n",
    "        X = scaler_X_all.transform(X)\n",
    "        \n",
    "        X_list.append(X)\n",
    "        X_scaler_list.append(scaler_X_all)\n",
    "        \n",
    "# kerPC\n",
    "elif model_type == \"kerPC\":\n",
    "    # Save initial list with kerPCs based on marker set\n",
    "    X_list_initial = []\n",
    "    \n",
    "    # Define marker sets\n",
    "    if m_set == \"SNP\":\n",
    "        marker_sets = [\"SNP\"]\n",
    "    elif m_set == \"all\":\n",
    "        marker_sets = [\"DEL\", \"DUP\", \"INV\", \"MITE-DTX\", \"RLX-RIX\", \"SNP\"]\n",
    "    \n",
    "    # Load matrices\n",
    "    for i in range(len(marker_sets)):\n",
    "        X_name = f\"PC_{marker_sets[i]}.csv\"\n",
    "        X_df = pd.read_csv(os.path.join(\"data\", model_type, X_name))\n",
    "        X_df = X_df.iloc[:, 1:]\n",
    "        \n",
    "        X = X_df.to_numpy()\n",
    "        X_list_initial.append(X)\n",
    "    \n",
    "    # Process depending on input-type\n",
    "    X_list = []\n",
    "    X_scaler_list = []\n",
    "    \n",
    "    # If single-input, concatenate matrices of list\n",
    "    if input_type == \"single-input\":\n",
    "        for i in range(len(X_list_initial)):\n",
    "            if i == 0:\n",
    "                X = X_list_initial[i]\n",
    "                continue\n",
    "            \n",
    "            X = np.concatenate((X, X_list_initial[i]), axis = 1)\n",
    "        \n",
    "        # Scale using all data because genomic prediction\n",
    "        scaler_X_all = StandardScaler()\n",
    "        scaler_X_all.fit(X)\n",
    "        X = scaler_X_all.transform(X)\n",
    "        \n",
    "        X_list.append(X)\n",
    "        X_scaler_list.append(scaler_X_all)\n",
    "    # Multi-input\n",
    "    else:\n",
    "        for i in range(len(X_list_initial)):\n",
    "            X = X_list_initial[i]\n",
    "            \n",
    "            # Scale using all data because genomic prediction\n",
    "            scaler_X_all = StandardScaler()\n",
    "            scaler_X_all.fit(X)\n",
    "            X = scaler_X_all.transform(X)\n",
    "            \n",
    "            X_list.append(X)\n",
    "            X_scaler_list.append(scaler_X_all)\n",
    "\n",
    "print(len(X_list))\n",
    "print(X_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608 34\n",
      "1 1\n",
      "(608, 10000) (34, 10000) (486, 10000) (122, 10000)\n",
      "(608, 1) (34, 1) (486, 1) (122, 1)\n"
     ]
    }
   ],
   "source": [
    "# Target =================================================================================\n",
    "\n",
    "Y_df = pd.read_csv(os.path.join(\"data\", \"pheno_original.csv\"))\n",
    "parts = pd.read_csv(os.path.join(\"data\", \"partitions.csv\"))\n",
    "\n",
    "# Obtain train and test masks ############################################################\n",
    "# Single-output\n",
    "if output_type == \"single-output\":\n",
    "    y_df = Y_df[traits[0]]\n",
    "    y = y_df.to_numpy().reshape(-1, 1)\n",
    "\n",
    "    train_mask = (parts[part] == \"train\") & pd.notna(y_df)\n",
    "    test_mask = (parts[part] == \"test\") & pd.notna(y_df)\n",
    "# Multi-output\n",
    "else:\n",
    "    # Obtain combined mask of missing values for the different traits (final_NA_mask)\n",
    "    NA_mask_list = []\n",
    "    for i in range(len(traits)):\n",
    "        y_df = Y_df[traits[i]]\n",
    "        \n",
    "        NA_mask = pd.notna(y_df)\n",
    "        NA_mask_list.append(NA_mask)\n",
    "    \n",
    "    for i in range(len(NA_mask_list)):\n",
    "        if i == 0:\n",
    "            final_NA_mask = NA_mask_list[i]\n",
    "            continue\n",
    "        final_NA_mask = final_NA_mask & NA_mask_list[i]\n",
    "        # print(initial_mask_list[i].sum())\n",
    "        print(final_NA_mask.sum())\n",
    "    \n",
    "    train_mask = (parts[part] == \"train\") & final_NA_mask\n",
    "    test_mask = (parts[part] == \"test\") & final_NA_mask\n",
    "    \n",
    "print(train_mask.sum(), test_mask.sum())\n",
    "\n",
    "# Train / test split + train_sub / validation split ######################################\n",
    "\n",
    "# Dicts of y splits for each trait (output)\n",
    "y_train = {}; y_test = {}; y_train_sub = {}; y_val = {}\n",
    "# y_train_scaler_dict = {}\n",
    "\n",
    "for i in range(len(traits)):\n",
    "    y_df = Y_df[traits[i]]\n",
    "    y = y_df.to_numpy().reshape(-1, 1)\n",
    "    \n",
    "    key = traits[i]\n",
    "    \n",
    "    # 1. Target split\n",
    "    \n",
    "    y_train_i = y[train_mask, ]\n",
    "    y_test_i = y[test_mask, ]\n",
    "    \n",
    "    # 2. Target process\n",
    "\n",
    "    # Scale continuous targets (just with train data)\n",
    "    # We no longer scale targets\n",
    "    if target_types[i] == \"continuous\":\n",
    "        # scaler_y_train = StandardScaler()\n",
    "        # scaler_y_train.fit(y_train_i)\n",
    "        # y_train_i = scaler_y_train.transform(y_train_i)\n",
    "        # y_test_i = scaler_y_train.transform(y_test_i)\n",
    "        \n",
    "        # y_train_scaler_dict[key] = scaler_y_train\n",
    "        pass\n",
    "    # Recode binary targets from 1/2 to 0/1\n",
    "    elif target_types[i] == \"binary\":\n",
    "        y_train_i = np.where(y_train_i == 2, 1, 0)\n",
    "        y_test_i = np.where(y_test_i == 2, 1, 0)\n",
    "    else:\n",
    "        print(\"Unknown target variable type\")\n",
    "        exit(1)\n",
    "    \n",
    "    y_train[key] = y_train_i\n",
    "    y_test[key] = y_test_i\n",
    "    \n",
    "    # 3. Features split\n",
    "    \n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    \n",
    "    X_train_sub = []\n",
    "    X_val = []\n",
    "    \n",
    "    # For every input\n",
    "    for j in range(len(X_list)):\n",
    "        X_train.append(X_list[j][train_mask, ])\n",
    "        X_test.append(X_list[j][test_mask, ])\n",
    "        \n",
    "        # RS seed is important in this case to have the same splits\n",
    "        X_train_sub_i, X_val_i, y_train_sub_i, y_val_i = train_test_split(\n",
    "            X_train[j], y_train_i,\n",
    "            test_size = 0.2,\n",
    "            random_state = RS\n",
    "        )\n",
    "        X_train_sub.append(X_train_sub_i)\n",
    "        X_val.append(X_val_i)\n",
    "    \n",
    "    y_train_sub[key] = y_train_sub_i\n",
    "    y_val[key] = y_val_i\n",
    "\n",
    "# X_lists and y_dicts\n",
    "print(len(X_train), len(y_train.keys()))\n",
    "\n",
    "print(X_train[0].shape, X_test[0].shape, X_train_sub[0].shape, X_val[0].shape)\n",
    "print(y_train[traits[0]].shape, y_test[traits[0]].shape,\n",
    "      y_train_sub[traits[0]].shape, y_val[traits[0]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load hypermodels and create corresponding object ------------------------------------\n",
    "\n",
    "from hypermodels import hyper_MLP\n",
    "from hypermodels import hyper_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,) ['time.to.flowering.from.sowing'] ['continuous'] 1 1\n"
     ]
    }
   ],
   "source": [
    "input_dim = (X_train[0].shape[1], )\n",
    "n_inputs = len(X_train)\n",
    "n_outputs = len(traits)\n",
    "print(input_dim, traits, target_types, n_inputs, n_outputs)\n",
    "\n",
    "\n",
    "if architecture == \"MLP\":\n",
    "    hypermodel = hyper_MLP(\n",
    "        input_dim = input_dim, targets = traits, target_types = target_types,\n",
    "        n_inputs = n_inputs, n_outputs = n_outputs\n",
    "    )\n",
    "elif architecture == \"CNN\":\n",
    "    hypermodel = hyper_CNN(\n",
    "        input_dim = input_dim, targets = traits, target_types = target_types,\n",
    "        n_inputs = n_inputs, n_outputs = n_outputs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = hypermodel.build(kt.HyperParameters())\n",
    "# model.summary()\n",
    "# history = model.fit(x = X_train, y = y_train, epochs = 10, validation_data = (X_val, y_val))\n",
    "# model.evaluate(x = X_test, y = y_test, return_dict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 23:40:21.402949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 5. Create tuner object -----------------------------------------------------------------\n",
    "\n",
    "# mse for continuous traits, binary_crossentropy for binary traits\n",
    "objective = \"val_loss\"\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel,\n",
    "    objective = objective,\n",
    "    max_epochs = 15,\n",
    "    hyperband_iterations = 1,\n",
    "    directory = out_folder,\n",
    "    project_name = \"tuning\",\n",
    "    overwrite = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 7\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'linear', 'softplus'], 'ordered': False}\n",
      "regularization_type (Choice)\n",
      "{'default': 'L2', 'conditions': [], 'values': ['L2', 'L1'], 'ordered': False}\n",
      "regularization_rate (Choice)\n",
      "{'default': 0.0, 'conditions': [], 'values': [0.0, 0.1, 0.01, 0.001], 'ordered': True}\n",
      "n_filters (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64, 128], 'ordered': True}\n",
      "n_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': None}\n",
      "units_0 (Choice)\n",
      "{'default': 10, 'conditions': [], 'values': [10, 20, 40, 80, 160], 'ordered': True}\n",
      "dropout_rate (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.3, 'step': 0.05, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 02s]\n",
      "val_loss: 0.7065833806991577\n",
      "\n",
      "Best val_loss So Far: 0.7065833806991577\n",
      "Total elapsed time: 00h 00m 26s\n",
      "\n",
      "Search: Running Trial #6\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "softplus          |tanh              |activation\n",
      "L2                |L2                |regularization_type\n",
      "0                 |0                 |regularization_rate\n",
      "128               |16                |n_filters\n",
      "2                 |1                 |n_layers\n",
      "40                |40                |units_0\n",
      "0.25              |0.15              |dropout_rate\n",
      "80                |40                |units_1\n",
      "80                |80                |units_2\n",
      "160               |80                |units_3\n",
      "40                |80                |units_4\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n",
      "16/16 - 6s - loss: 15723.2246 - mse: 15723.2246 - val_loss: 3.1985 - val_mse: 3.1985 - 6s/epoch - 396ms/step\n",
      "Epoch 2/2\n"
     ]
    }
   ],
   "source": [
    "# 6. Hyperparameter search ---------------------------------------------------------------\n",
    "\n",
    "# Remove previous tensorboard logs\n",
    "log_dir = os.path.join(out_folder,\"tuning_tb-logs\")\n",
    "if os.path.isdir(log_dir):\n",
    "    for file in os.listdir(log_dir):\n",
    "        file_path = os.path.join(log_dir, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "\n",
    "# Search\n",
    "\n",
    "callbacks = [\n",
    "    # Tensorboard training logs\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir = log_dir\n",
    "    ),\n",
    "    # Early stopping\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor = \"val_loss\",\n",
    "        patience = 10,\n",
    "        min_delta = 0.001,\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "]\n",
    "\n",
    "tuner.search(x = X_train_sub, y = y_train_sub,\n",
    "             validation_data = (X_val, y_val),\n",
    "             callbacks = callbacks,\n",
    "             verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anavartinez/CRAG_not_tracked/riceDL_2_main/alex/Python/models/top-markers-10k_MLP_SNP_single-input/grain.weight/AroAdm/tuning_tb-logs\n"
     ]
    }
   ],
   "source": [
    "# Visualize tuning results\n",
    "\n",
    "# It's probably too many files to visualize them, but run on terminal:\n",
    "\n",
    "# conda activate tf2\n",
    "# tensorboard --logdir log_dir\n",
    "\n",
    "print(os.path.realpath(log_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in models/top-markers-10k_MLP_SNP_single-input/grain.weight/AroAdm/tuning\n",
      "Showing 1 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7f235d7ee910>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "activation: softplus\n",
      "regularization_type: L2\n",
      "regularization_rate: 0.0\n",
      "n_layers: 4\n",
      "units_0: 80\n",
      "dropout_rate: 0.15000000000000002\n",
      "units_1: 40\n",
      "units_2: 20\n",
      "units_3: 80\n",
      "units_4: 40\n",
      "tuner/epochs: 15\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0014\n",
      "Score: 0.15594035387039185\n"
     ]
    }
   ],
   "source": [
    "# Best hpars\n",
    "tuner.results_summary(num_trials = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Record tuning results ---------------------------------------------------------------\n",
    "\n",
    "# Save best 100 hpars\n",
    "top_hps = tuner.get_best_hyperparameters(100)\n",
    "\n",
    "# Create folder\n",
    "hps_path = os.path.join(out_folder, \"top_hps\")\n",
    "if not os.path.isdir(hps_path):\n",
    "    os.mkdir(hps_path)\n",
    "\n",
    "# Save as dictionaries (.json)\n",
    "for j in range(len(top_hps)):\n",
    "    hps_dict = top_hps[j].values\n",
    "    \n",
    "    with open(os.path.join(hps_path, f\"top_hps_{j + 1}.json\"), \"w\") as outfile:\n",
    "        json.dump(hps_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erase tuning results (they take about 25 Gb) ===========================================\n",
    "tuner_dir = os.path.join(out_folder, \"tuning\")\n",
    "if os.path.isdir(tuner_dir):\n",
    "    for file in os.listdir(tuner_dir):\n",
    "        file_path = os.path.join(tuner_dir, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10000)]           0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 80)                800080    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 40)                3240      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 80)                1680      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " grain.weight (Dense)        (None, 1)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805,901\n",
      "Trainable params: 805,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: models/top-markers-10k_MLP_SNP_single-input/grain.weight/AroAdm/best_model/best_model.tf/assets\n"
     ]
    }
   ],
   "source": [
    "# 8. Prediction --------------------------------------------------------------------------\n",
    "\n",
    "# Create model with best hpars\n",
    "best_hps = top_hps[0]\n",
    "model = hypermodel.build(best_hps)\n",
    "model.summary()\n",
    "\n",
    "# Save best model\n",
    "best_model_path = os.path.join(out_folder, \"best_model\")\n",
    "if not os.path.isdir(best_model_path):\n",
    "    os.mkdir(best_model_path)\n",
    "\n",
    "model.save(os.path.join(best_model_path, \"best_model.tf\"))\n",
    "\n",
    "with open(os.path.join(best_model_path, \"best_hps.json\"), \"w\") as outfile:\n",
    "    json.dump(best_hps.values, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 - 0s - loss: 9.0094 - mse: 9.0094 - val_loss: 1.7392 - val_mse: 1.7392 - 439ms/epoch - 27ms/step\n",
      "Epoch 2/50\n",
      "16/16 - 0s - loss: 3.6110 - mse: 3.6110 - val_loss: 0.4589 - val_mse: 0.4589 - 59ms/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "16/16 - 0s - loss: 2.1269 - mse: 2.1269 - val_loss: 0.5203 - val_mse: 0.5203 - 55ms/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "16/16 - 0s - loss: 1.1878 - mse: 1.1878 - val_loss: 0.4040 - val_mse: 0.4040 - 58ms/epoch - 4ms/step\n",
      "Epoch 5/50\n",
      "16/16 - 0s - loss: 1.0922 - mse: 1.0922 - val_loss: 0.4867 - val_mse: 0.4867 - 54ms/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "16/16 - 0s - loss: 1.4012 - mse: 1.4012 - val_loss: 0.3893 - val_mse: 0.3893 - 73ms/epoch - 5ms/step\n",
      "Epoch 7/50\n",
      "16/16 - 0s - loss: 0.8017 - mse: 0.8017 - val_loss: 0.5581 - val_mse: 0.5581 - 55ms/epoch - 3ms/step\n",
      "Epoch 8/50\n",
      "16/16 - 0s - loss: 0.8291 - mse: 0.8291 - val_loss: 0.3344 - val_mse: 0.3344 - 57ms/epoch - 4ms/step\n",
      "Epoch 9/50\n",
      "16/16 - 0s - loss: 0.7705 - mse: 0.7705 - val_loss: 0.3188 - val_mse: 0.3188 - 75ms/epoch - 5ms/step\n",
      "Epoch 10/50\n",
      "16/16 - 0s - loss: 0.7810 - mse: 0.7810 - val_loss: 0.3380 - val_mse: 0.3380 - 52ms/epoch - 3ms/step\n",
      "Epoch 11/50\n",
      "16/16 - 0s - loss: 0.4946 - mse: 0.4946 - val_loss: 0.1590 - val_mse: 0.1590 - 56ms/epoch - 3ms/step\n",
      "Epoch 12/50\n",
      "16/16 - 0s - loss: 0.4686 - mse: 0.4686 - val_loss: 0.3834 - val_mse: 0.3834 - 51ms/epoch - 3ms/step\n",
      "Epoch 13/50\n",
      "16/16 - 0s - loss: 0.4590 - mse: 0.4590 - val_loss: 0.2049 - val_mse: 0.2049 - 53ms/epoch - 3ms/step\n",
      "Epoch 14/50\n",
      "16/16 - 0s - loss: 0.4421 - mse: 0.4421 - val_loss: 0.2757 - val_mse: 0.2757 - 68ms/epoch - 4ms/step\n",
      "Epoch 15/50\n",
      "16/16 - 0s - loss: 0.3373 - mse: 0.3373 - val_loss: 0.1435 - val_mse: 0.1435 - 55ms/epoch - 3ms/step\n",
      "Epoch 16/50\n",
      "16/16 - 0s - loss: 0.3217 - mse: 0.3217 - val_loss: 0.2120 - val_mse: 0.2120 - 52ms/epoch - 3ms/step\n",
      "Epoch 17/50\n",
      "16/16 - 0s - loss: 0.3358 - mse: 0.3358 - val_loss: 0.2996 - val_mse: 0.2996 - 52ms/epoch - 3ms/step\n",
      "Epoch 18/50\n",
      "16/16 - 0s - loss: 0.3186 - mse: 0.3186 - val_loss: 0.1448 - val_mse: 0.1448 - 51ms/epoch - 3ms/step\n",
      "Epoch 19/50\n",
      "16/16 - 0s - loss: 0.2980 - mse: 0.2980 - val_loss: 0.1672 - val_mse: 0.1672 - 53ms/epoch - 3ms/step\n",
      "Epoch 20/50\n",
      "16/16 - 0s - loss: 0.2823 - mse: 0.2823 - val_loss: 0.2372 - val_mse: 0.2372 - 53ms/epoch - 3ms/step\n",
      "Epoch 21/50\n",
      "16/16 - 0s - loss: 0.2628 - mse: 0.2628 - val_loss: 0.1790 - val_mse: 0.1790 - 51ms/epoch - 3ms/step\n",
      "Epoch 22/50\n",
      "16/16 - 0s - loss: 0.2686 - mse: 0.2686 - val_loss: 0.1941 - val_mse: 0.1941 - 52ms/epoch - 3ms/step\n",
      "Epoch 23/50\n",
      "16/16 - 0s - loss: 0.2951 - mse: 0.2951 - val_loss: 0.1544 - val_mse: 0.1544 - 53ms/epoch - 3ms/step\n",
      "Epoch 24/50\n",
      "16/16 - 0s - loss: 0.2281 - mse: 0.2281 - val_loss: 0.1595 - val_mse: 0.1595 - 57ms/epoch - 4ms/step\n",
      "Epoch 25/50\n",
      "16/16 - 0s - loss: 0.2061 - mse: 0.2061 - val_loss: 0.1361 - val_mse: 0.1361 - 55ms/epoch - 3ms/step\n",
      "Epoch 26/50\n",
      "16/16 - 0s - loss: 0.2188 - mse: 0.2188 - val_loss: 0.1975 - val_mse: 0.1975 - 52ms/epoch - 3ms/step\n",
      "Epoch 27/50\n",
      "16/16 - 0s - loss: 0.2201 - mse: 0.2201 - val_loss: 0.1603 - val_mse: 0.1603 - 53ms/epoch - 3ms/step\n",
      "Epoch 28/50\n",
      "16/16 - 0s - loss: 0.1641 - mse: 0.1641 - val_loss: 0.1230 - val_mse: 0.1230 - 56ms/epoch - 4ms/step\n",
      "Epoch 29/50\n",
      "16/16 - 0s - loss: 0.1684 - mse: 0.1684 - val_loss: 0.1987 - val_mse: 0.1987 - 56ms/epoch - 4ms/step\n",
      "Epoch 30/50\n",
      "16/16 - 0s - loss: 0.2242 - mse: 0.2242 - val_loss: 0.1454 - val_mse: 0.1454 - 51ms/epoch - 3ms/step\n",
      "Epoch 31/50\n",
      "16/16 - 0s - loss: 0.1627 - mse: 0.1627 - val_loss: 0.1490 - val_mse: 0.1490 - 56ms/epoch - 4ms/step\n",
      "Epoch 32/50\n",
      "16/16 - 0s - loss: 0.1473 - mse: 0.1473 - val_loss: 0.1706 - val_mse: 0.1706 - 59ms/epoch - 4ms/step\n",
      "Epoch 33/50\n",
      "16/16 - 0s - loss: 0.1574 - mse: 0.1574 - val_loss: 0.1385 - val_mse: 0.1385 - 55ms/epoch - 3ms/step\n",
      "Epoch 34/50\n",
      "16/16 - 0s - loss: 0.1317 - mse: 0.1317 - val_loss: 0.1796 - val_mse: 0.1796 - 56ms/epoch - 3ms/step\n",
      "Epoch 35/50\n",
      "16/16 - 0s - loss: 0.1469 - mse: 0.1469 - val_loss: 0.1454 - val_mse: 0.1454 - 55ms/epoch - 3ms/step\n",
      "Epoch 36/50\n",
      "16/16 - 0s - loss: 0.1521 - mse: 0.1521 - val_loss: 0.1987 - val_mse: 0.1987 - 54ms/epoch - 3ms/step\n",
      "Epoch 37/50\n",
      "16/16 - 0s - loss: 0.1714 - mse: 0.1714 - val_loss: 0.1752 - val_mse: 0.1752 - 57ms/epoch - 4ms/step\n",
      "Epoch 38/50\n",
      "16/16 - 0s - loss: 0.1796 - mse: 0.1796 - val_loss: 0.1629 - val_mse: 0.1629 - 56ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Training with early stopping. Use validation set\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor = \"val_loss\",\n",
    "        patience = 10,\n",
    "        min_delta = 0.001,\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "]\n",
    "\n",
    "history = hypermodel.fit(\n",
    "    best_hps, model,\n",
    "    x = X_train_sub, y = y_train_sub,\n",
    "    epochs = 50,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = (X_val, y_val),\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/top-markers-10k_MLP_SNP_single-input/grain.weight/AroAdm\n"
     ]
    }
   ],
   "source": [
    "print(out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8120 - mse: 0.8120\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss                  0.812044\n",
      "mse                   0.812044\n",
      "size_train          607.000000\n",
      "size_test            34.000000\n",
      "size_total          641.000000\n",
      "grain.weight_cor      0.216706\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save prediction results\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "pred_path = os.path.join(out_folder, \"results\")\n",
    "if not os.path.isdir(pred_path):\n",
    "    os.mkdir(pred_path)\n",
    "\n",
    "# Training plot\n",
    "plt.plot(history.history[\"loss\"], label = \"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label = \"val_loss\")\n",
    "plt.legend(loc = \"upper right\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(os.path.join(pred_path, \"training_loss_plot.png\"), dpi = 300)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# Compute metrics and prediction\n",
    "eval_result = model.evaluate(x = X_test, y = y_test, return_dict = True)\n",
    "pred_result = model.predict(X_test)\n",
    "\n",
    "# Series of results\n",
    "res = pd.Series(eval_result)\n",
    "\n",
    "# Dataset size\n",
    "size_train = y_train[traits[0]].shape[0]\n",
    "size_test = y_test[traits[0]].shape[0]\n",
    "size_total = size_train + size_test\n",
    "\n",
    "res[\"size_train\"] = size_train\n",
    "res[\"size_test\"] = size_test\n",
    "res[\"size_total\"] = size_total\n",
    "\n",
    "# Compute extra metrics and do plots, depending on target type\n",
    "\n",
    "for i in range(len(target_types)):\n",
    "    y_test_i = y_test[traits[i]]\n",
    "    \n",
    "    if target_types[i] == \"continuous\":\n",
    "        # Correlation\n",
    "        if output_type == \"single-output\":\n",
    "            pred_result_i = pred_result\n",
    "        else:\n",
    "            pred_result_i = pred_result[i]\n",
    "        \n",
    "        y_hat = pred_result_i\n",
    "        cor = np.corrcoef(y_test_i, y_hat, rowvar = False)[0, 1]\n",
    "        res[f\"{traits[i]}_cor\"] = cor\n",
    "        \n",
    "        # Correlation plot\n",
    "        plot = sns.scatterplot(x = y_test_i.squeeze(), y = y_hat.squeeze())\n",
    "        plot.set(xlabel = \"y_test\", ylabel = \"y_hat\", title = traits[i])\n",
    "        plt.savefig(os.path.join(pred_path, f\"cor_plot_{traits[i]}.png\"), dpi = 300)\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "    \n",
    "    elif target_types[i] == \"binary\":\n",
    "        # AUC\n",
    "        if output_type == \"single-output\":\n",
    "            pred_result_i = pred_result\n",
    "        else:\n",
    "            pred_result_i = pred_result[i]\n",
    "        m = keras.metrics.AUC()\n",
    "        m.update_state(y_test_i, pred_result_i)\n",
    "        AUC = m.result().numpy()\n",
    "        res[f\"{traits[i]}_AUC\"] = AUC\n",
    "        \n",
    "        # Confusion matrix plot\n",
    "        y_hat = np.where(pred_result_i > 0.5, 1, 0)\n",
    "        conf = confusion_matrix(y_test_i, y_hat)\n",
    "        plot = sns.heatmap(conf, annot = True, cmap = \"Blues\")\n",
    "        plot.set(xlabel = \"y_hat\", ylabel = \"y_test\", title = traits[i])\n",
    "        plt.savefig(os.path.join(pred_path, f\"conf_matrix_{traits[i]}.png\"), dpi = 300)\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "    \n",
    "    # Save prediction just in case\n",
    "    prediction = pd.DataFrame({\n",
    "        \"original_index\": test_mask.index[test_mask == True],\n",
    "        \"prediction\": pred_result_i.squeeze() \n",
    "    })\n",
    "    prediction.to_csv(os.path.join(pred_path, f\"prediction_{traits[i]}.csv\"),\n",
    "                      index = False, header = True)\n",
    "    \n",
    "print(res)\n",
    "res.to_csv(os.path.join(pred_path, \"results.csv\"), index = True, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12b52cd0ece1e2f7012b6dd52d9d70760d6fcae4e81bf4d86c9345b36e072371"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
